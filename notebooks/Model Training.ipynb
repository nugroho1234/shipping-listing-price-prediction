{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e417cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from unidecode import unidecode\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "#nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from langdetect import detect\n",
    "\n",
    "#preprocessing and feature extraction\n",
    "import helper\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.utils import FeatureSpace\n",
    "\n",
    "from tensorflow import feature_column as fc\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae46955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(parent_dir + '\\\\' + 'data/online_ship_listing_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca450e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184 train examples\n",
      "296 validation examples\n",
      "370 test examples\n"
     ]
    }
   ],
   "source": [
    "#splitting the dataframe\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bac7ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(df, shuffle=True, batch_size=32):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df = helper.preprocess_df(df)\n",
    "    df, all_cols = helper.create_features(df)\n",
    "    labels = df.pop('price')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(df))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds, all_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b72c561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Online Course\\Projects\\shipping-listing-price-prediction\\helper.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(['word_count'], axis=1, inplace=True)\n",
      "C:\\Online Course\\Projects\\shipping-listing-price-prediction\\helper.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['description_language'] = df['description'].apply(lambda x:detect(x))\n",
      "C:\\Online Course\\Projects\\shipping-listing-price-prediction\\helper.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(['word_count'], axis=1, inplace=True)\n",
      "C:\\Online Course\\Projects\\shipping-listing-price-prediction\\helper.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['description_language'] = df['description'].apply(lambda x:detect(x))\n"
     ]
    }
   ],
   "source": [
    "#convert dataframe to dataset\n",
    "batch_size = 32\n",
    "train_ds, all_cols = df_to_dataset(train)\n",
    "val_ds, _ = df_to_dataset(val, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30b06dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['year', 'model', 'category', 'length', 'fuel_type', 'hull_material', 'country', 'noun_counts', 'verb_counts', 'adjective_counts', 'bilge_pump', 'deck_finish', 'fuel_tank', 'good_condition', 'level_indicator', 'material_grp', 'sailing_yacht', 'stainless_steel', 'tank_litre', 'teak_cockpit', 'avg_price_by_hull_material', 'avg_price_by_fuel_type', 'avg_price_by_category']\n",
      "A batch of fuel tank: tf.Tensor(\n",
      "[b'diesel' b'electrical' b'diesel' b'diesel' b'diesel' b'diesel' b'diesel'\n",
      " b'petrol' b'diesel' b'diesel' b'diesel' b'diesel' b'diesel' b'diesel'\n",
      " b'diesel' b'diesel' b'diesel' b'diesel' b'diesel' b'diesel' b'diesel'\n",
      " b'diesel' b'diesel' b'diesel' b'diesel' b'diesel' b'diesel' b'diesel'\n",
      " b'diesel' b'diesel' b'diesel' b'diesel'], shape=(32,), dtype=string)\n",
      "A batch of country: tf.Tensor(\n",
      "[b'spain' b'austria' b'spain' b'afghanistan' b'france' b'afghanistan'\n",
      " b'netherlands' b'italy' b'afghanistan' b'italy' b'germany' b'afghanistan'\n",
      " b'netherlands' b'spain' b'afghanistan' b'germany' b'italy' b'netherlands'\n",
      " b'afghanistan' b'italy' b'afghanistan' b'afghanistan' b'netherlands'\n",
      " b'france' b'netherlands' b'afghanistan' b'germany' b'spain' b'italy'\n",
      " b'afghanistan' b'grenada' b'spain'], shape=(32,), dtype=string)\n",
      "A batch of model: tf.Tensor(\n",
      "[b'slup_boote' b'segelboote_mit_kajte' b'slup_boote'\n",
      " b'katamarane_und_trimarane' b'segelyachten' b'segelyachten' b'slup_boote'\n",
      " b'segelyachten' b'klassische_segelboote' b'katamarane' b'segelyachten'\n",
      " b'segelyachten' b'slup_boote' b'segelyachten' b'segelyachten'\n",
      " b'segelboote_mit_kajte' b'segelyachten' b'slup_boote' b'slup_boote'\n",
      " b'sonstige_segelboote' b'segelyachten' b'daysailers' b'slup_boote'\n",
      " b'daysailers' b'slup_boote' b'segelyachten' b'sonstige_segelboote'\n",
      " b'segelyachten' b'katamarane_und_trimarane' b'segelyachten'\n",
      " b'segelyachten' b'racer_cruiser_segelboote'], shape=(32,), dtype=string)\n",
      "A batch of targets: tf.Tensor(\n",
      "[440000.  14500. 139000. 379000. 560000.  68242.  49900.  24000.  75000.\n",
      " 389539.  86000. 395000.  99000.  15000.   2843.  13000. 515811. 195000.\n",
      " 119900. 568000. 159000.  57500.  29500.  69000.  54500. 345758.  44900.\n",
      "  89995. 198500. 229000. 142808.  59000.], shape=(32,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "#sanity checking\n",
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "    print('Every feature:', list(feature_batch.keys()))\n",
    "    print('A batch of fuel tank:', feature_batch['fuel_type'])\n",
    "    print('A batch of country:', feature_batch['country'])\n",
    "    print('A batch of model:', feature_batch['category'])\n",
    "    print('A batch of targets:', label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc3ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = parent_dir + '\\\\' + 'model/column_names.pkl'\n",
    "with open(fileName,'wb') as f:\n",
    "    pickle.dump(all_cols,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cfaee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_normalized_cols = ['length', 'noun_counts', 'verb_counts', 'adjective_counts', 'avg_price_by_hull_material',\n",
    "                        'avg_price_by_fuel_type', 'avg_price_by_category']\n",
    "float_cols = ['bilge_pump', 'deck_finish', 'fuel_tank', 'level_indicator', 'material_grp', 'mehr_anzeigen',\n",
    "             'sailing_yacht', 'stainless_steel', 'tank_litre', 'teak_cockpit']\n",
    "string_categorical_cols = ['model', 'category', 'hull_material', 'country', 'fuel_type']\n",
    "float_discretized_cols = ['year']\n",
    "\n",
    "float_normalized = 'float_normalized'\n",
    "just_float = 'float'\n",
    "string_categorical = 'string_categorical'\n",
    "float_discretized = 'float_discretized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b652f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = sorted(float_normalized_cols + float_cols + string_categorical_cols)\n",
    "features_dict = {key: float_normalized if key in float_normalized_cols else (just_float if key in float_cols else string_categorical) for key in all_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41ace377",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict['year'] = FeatureSpace.float_discretized(num_bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10165a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adjective_counts': 'float_normalized',\n",
       " 'avg_price_by_category': 'float_normalized',\n",
       " 'avg_price_by_fuel_type': 'float_normalized',\n",
       " 'avg_price_by_hull_material': 'float_normalized',\n",
       " 'bilge_pump': 'float',\n",
       " 'category': 'string_categorical',\n",
       " 'country': 'string_categorical',\n",
       " 'deck_finish': 'float',\n",
       " 'fuel_tank': 'float',\n",
       " 'fuel_type': 'string_categorical',\n",
       " 'hull_material': 'string_categorical',\n",
       " 'length': 'float_normalized',\n",
       " 'level_indicator': 'float',\n",
       " 'material_grp': 'float',\n",
       " 'mehr_anzeigen': 'float',\n",
       " 'model': 'string_categorical',\n",
       " 'noun_counts': 'float_normalized',\n",
       " 'sailing_yacht': 'float',\n",
       " 'stainless_steel': 'float',\n",
       " 'tank_litre': 'float',\n",
       " 'teak_cockpit': 'float',\n",
       " 'verb_counts': 'float_normalized',\n",
       " 'year': <keras.src.utils.feature_space.Feature at 0x27567aaad10>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e32da840",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FeatureSpace' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 36\u001b[0m\n\u001b[0;32m      1\u001b[0m feature_space \u001b[38;5;241m=\u001b[39m FeatureSpace(\n\u001b[0;32m      2\u001b[0m     features\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madjective_counts\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat_normalized\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     ],\n\u001b[0;32m     34\u001b[0m )\n\u001b[1;32m---> 36\u001b[0m feature_space_test \u001b[38;5;241m=\u001b[39m feature_space\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#needs to adapt the feature_space. Reminder: feature_space needs to be adapted to a dataset WITHOUT LABEL\u001b[39;00m\n\u001b[0;32m     39\u001b[0m train_ds_with_no_labels \u001b[38;5;241m=\u001b[39m train_ds\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x, _: x)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FeatureSpace' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "    \"adjective_counts\": 'float_normalized',\n",
    "    \"avg_price_by_category\": 'float_normalized',\n",
    "    \"avg_price_by_fuel_type\": 'float_normalized',\n",
    "    \"avg_price_by_hull_material\": 'float_normalized',\n",
    "    \"bilge_pump\": 'float',\n",
    "    \"category\": 'string_categorical',\n",
    "    \"country\": 'string_categorical',\n",
    "    \"deck_finish\": 'float',\n",
    "    \"fuel_tank\": 'float',\n",
    "    \"fuel_type\": 'string_categorical',\n",
    "    \"hull_material\": 'string_categorical',\n",
    "    \"length\": 'float_normalized',\n",
    "    \"level_indicator\": 'float',\n",
    "    \"material_grp\": 'float',\n",
    "    \"good_condition\": 'float',\n",
    "    \"model\": 'string_categorical',\n",
    "    \"noun_counts\": 'float_normalized',\n",
    "    \"sailing_yacht\": 'float',\n",
    "    \"stainless_steel\": 'float',\n",
    "    \"tank_litre\": 'float',\n",
    "    \"teak_cockpit\": 'float',\n",
    "    \"verb_counts\": 'float_normalized',\n",
    "    \"year\": FeatureSpace.float_discretized(num_bins=10)\n",
    "    },\n",
    "    output_mode=\"concat\",\n",
    "    crosses=[\n",
    "        FeatureSpace.cross(feature_names=(\"model\", \"category\"), crossing_dim=64),\n",
    "        FeatureSpace.cross(feature_names=(\"hull_material\", \"category\"), crossing_dim=16),\n",
    "        FeatureSpace.cross(feature_names=(\"fuel_type\", \"category\"), crossing_dim=16),\n",
    "        \n",
    "    ],\n",
    ")\n",
    "\n",
    "feature_space_test = feature_space.copy()\n",
    "\n",
    "#needs to adapt the feature_space. Reminder: feature_space needs to be adapted to a dataset WITHOUT LABEL\n",
    "train_ds_with_no_labels = train_ds.map(lambda x, _: x)\n",
    "feature_space.adapt(train_ds_with_no_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb0eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_space.save(parent_dir + '\\\\' + 'model/feature_space.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7e1f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the dataset shape\n",
    "for x, _ in train_ds.take(1):\n",
    "    preprocessed_x = feature_space(x)\n",
    "    print(\"preprocessed_x.shape:\", preprocessed_x.shape)\n",
    "    print(\"preprocessed_x.dtype:\", preprocessed_x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7ca2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):  # Root mean square error\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c0804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remapping to label\n",
    "preprocessed_train_ds = train_ds.map(\n",
    "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "preprocessed_train_ds = preprocessed_train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "#To make sure the training data is read infinitely\n",
    "preprocessed_train_ds = preprocessed_train_ds.repeat()\n",
    "\n",
    "preprocessed_val_ds = val_ds.map(\n",
    "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "preprocessed_val_ds = preprocessed_val_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_inputs = feature_space.get_inputs()\n",
    "encoded_features = feature_space.get_encoded_features()\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(encoded_features)\n",
    "x = keras.layers.Dropout(0.5)(x) #using dropout layer to avoid overfitting\n",
    "x = keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "predictions = keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "#1st model: training_model\n",
    "training_model = keras.Model(inputs=encoded_features, outputs=predictions)\n",
    "training_model.compile(\n",
    "    optimizer=\"adam\", loss=\"mse\", metrics=[rmse, \"mse\"]\n",
    ")\n",
    "\n",
    "#2nd model: inference_model\n",
    "inference_model = keras.Model(inputs=dict_inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35885df",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 32 \n",
    "NUM_TRAIN_EXAMPLES = 59621 * 5\n",
    "NUM_EVALS = 500\n",
    "NUM_EVAL_EXAMPLES = 14906\n",
    "\n",
    "steps_per_epoch = NUM_TRAIN_EXAMPLES // (TRAIN_BATCH_SIZE * NUM_EVALS)\n",
    "#early stopping to avoid overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26421907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "history = training_model.fit(preprocessed_train_ds,\n",
    "                    validation_data=preprocessed_val_ds,\n",
    "                    epochs=NUM_EVALS,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    callbacks=[early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(history, metrics):\n",
    "    nrows = 1\n",
    "    ncols = 2\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "    for idx, key in enumerate(metrics):  \n",
    "        ax = fig.add_subplot(nrows, ncols, idx+1)\n",
    "        plt.plot(history.history[key])\n",
    "        plt.plot(history.history['val_{}'.format(key)])\n",
    "        plt.title('model {}'.format(key))\n",
    "        plt.ylabel(key)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper right');    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff47d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(history, ['loss', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a sample data\n",
    "sample = {\n",
    "    \"year\":tf.convert_to_tensor([2010.]),\n",
    "    \"model\":tf.convert_to_tensor(['gulet']),\n",
    "    \"category\":tf.convert_to_tensor(['schoner']),\n",
    "    \"length\":tf.convert_to_tensor([83.]),\n",
    "    \"fuel_type\":tf.convert_to_tensor(['diesel']),\n",
    "    \"hull_material\":tf.convert_to_tensor(['steel']),\n",
    "    \"country\":tf.convert_to_tensor(['turkey']),\n",
    "    \"noun_counts\":tf.convert_to_tensor([20.]),\n",
    "    \"verb_counts\":tf.convert_to_tensor([20.]),\n",
    "    \"adjective_counts\":tf.convert_to_tensor([20.]),\n",
    "    \"bilge_pump\":tf.convert_to_tensor([1.]),\n",
    "    \"deck_finish\":tf.convert_to_tensor([0.]),\n",
    "    \"fuel_tank\":tf.convert_to_tensor([1.]),\n",
    "    \"level_indicator\":tf.convert_to_tensor([1.]),\n",
    "    \"material_grp\":tf.convert_to_tensor([0.]),\n",
    "    \"good_condition\":tf.convert_to_tensor([0.]),\n",
    "    \"sailing_yacht\":tf.convert_to_tensor([1.]),\n",
    "    \"stainless_steel\":tf.convert_to_tensor([0.]),\n",
    "    \"tank_litre\":tf.convert_to_tensor([1.]),\n",
    "    \"teak_cockpit\":tf.convert_to_tensor([1.]),\n",
    "    \"avg_price_by_hull_material\":tf.convert_to_tensor([173764.8396226415]),\n",
    "    \"avg_price_by_fuel_type\":tf.convert_to_tensor([172121.64462209304]),\n",
    "    \"avg_price_by_category\":tf.convert_to_tensor([476125.0]),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760be385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model.save(parent_dir + '\\\\' + \"model/inference_model.keras\")\n",
    "reconstructed_model = load_model(parent_dir + '\\\\' + \"model/inference_model.keras\")\n",
    "reconstructed_model.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e5875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_temp = helper.preprocess_df(test)\n",
    "df_test,_ = helper.create_features(test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a587c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_price = df_test.price.tolist()\n",
    "df_test.drop('price', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b414a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = [row.to_dict() for _, row in df_test.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cf9080",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_price = []\n",
    "for i in list_of_dicts:\n",
    "    #convert the value of the dictionary to tensor\n",
    "    input_dict = {name: tf.convert_to_tensor([value]) for name, value in i.items()}\n",
    "    predictions = inference_model.predict(input_dict)\n",
    "    predicted_price.append(predictions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c44988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#appending the quantity and predicted quantity to the dataframe\n",
    "df_test['price'] = test_price\n",
    "df_test['predicted_price'] = predicted_price\n",
    "rmse = np.sqrt(mean_squared_error(df_test['price'], df_test['predicted_price']))\n",
    "\n",
    "print('The resulting RMSE for the test dataset is: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = load_model(parent_dir + '\\\\' + \"model/inference_model.keras\")\n",
    "reconstructed_model.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae37eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model.compile(\n",
    "    optimizer=\"adam\", loss=\"mse\", metrics=[rmse, \"mse\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22220392",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model.save(parent_dir + '\\\\' + 'model/tf_inference_model', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc00bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff09ab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Projects Env",
   "language": "python",
   "name": "mlprojects_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
